# Zabbix Low Level Discovery aggregator plugin

The Zabbix LLD aggregator plugin generates low level discovery trap metrics server each `period` with the info obtained from the metrics seen by the aggregator.

This metrics are expected to be sent to Zabbix using the Zabbix output plugin.

**[Zabbix 4.2](https://www.zabbix.com/documentation/4.2/manual/discovery/low_level_discovery)** has changed the LLD format and it is not currently supported.

#### Idea

Zabbix needs an `item` created before receiving any metric. In some cases we do not know in advance what are we going to send, for example, the name of a container to send its cpu and memory consumption.

For this case Zabbix provides [low level discovery](https://www.zabbix.com/documentation/4.0/manual/discovery/low_level_discovery) that allow to create dinamically new items based on the parameters sent by the trap.

This aggregator will see metrics generated by Telegraf and create LLD traps for a discovery key that should be present in the host receiving the traps in the Zabbix server.


#### Design

To explain how everything interconnects we will use an example with the `net_response` input:
```
[[inputs.net_response]]
  protocol = "tcp"
  address = "example.com:80"
```

This input will generate this metric:
```
$ telegraf -config example.conf -test
* Plugin: inputs.net_response, Collection 1
> net_response,server=example.com,port=80,protocol=tcp,host=myhost result_type="success",response_time=0.091026869 1522741063000000000
```

Here we have four tags: server, port, protocol and host (this one will be assumed that is always present and treated differently).

The values those three parameters could take are unknown to Zabbix, so we cannot create a trap in zabbix to receive that metric (at least without confussing that metric with another `net_response` metric with different tags).

To solve this problem we use a discovery rule in Zabbix, that will receive the different groups of tag values and create the traps to gather the metrics.

The aggregator knows about three tags (excluding host) for the input `net_response`, therefore it will generate this new Telegraf metric:
```
lld.host=myhost net_response.port.protocol.server="{\"data\":[{\"{#PORT}\":\"80\",\"{#PROTOCOL}\":\"tcp\",\"{#SERVER}\":\"example.com\"}]}"
```

If sent using the Zabbix output plugin, the final package will be:
```
{
  "request":"sender data",
  "data":[
    {
      "host":"myhost",
      "key":"lld.net_response.port.protocol.server",
      "value":"{\"data\":[{
          \"{#PORT}\":\"80\",
          \"{#PROTOCOL}\":\"tcp\",
          \"{#SERVER}\":\"example.com\"
      }]}",
      "clock":1519043805
    }
  ],
  "clock":1519043805
}
```

The key is generated joining `lld`, the input name and tags alphabetically sorted. Some inputs could use different groups of tags for different fields, that is why the tags are added to the key, to allow having different discovery rules for the same input.

The tags are changed to uppercase to match the format of Zabbix.

In the Zabbix server we should have a discovery rule associated with that key (lld.net_response.port.protocol.server) and one item prototype for each field, in this case `result_type` and `response_time`.

The item prototypes will be Zabbix trappers with keys (data type should also match and some values will be better stored as Delta):
```
net_response.response_time[{#PORT},#PROTOCOL},{#SERVER}]
net_response.result_type[{#PORT},{#PROTOCOL},{#SERVER}]
```

The macros in the item prototypes keys should be alphabetically sorted so they can match the keys generated by the zabbix output plugin.

With that keys and the example trap, the host `myhost` will have two new items:
```
net_response.response_time[80,tcp,example.com]
net_response.result_type[80,tcp,example.com]
```

The Zabbix output plugin, for each metric, will send traps to the Zabbix server following the same structure (INPUT.FIELD[tags sorted]...), filling the items created by the discovery rule.


To sump up:
 - we need a discovery rule with the correct key and one item prototype for each field
 - this aggregator will generate traps to create items based on the metrics seen in Telegraf
 - the output plugin will fill the new items

#### Reducing the number of LLDs
This aggregator remember which LLDs has been sent to Zabbix and avoid generating the same metrics again, to avoid the cost of LLD processing in Zabbix.

Each ``reset_period`` periods (by default 10 times), state is deleted and aggregator resend again already seen LLDs.
The idea behind this "reset" is to resend LLDs that could be lost in previous sent to Zabbix.


### Configuration:

```toml
# Send to Zabbix a LLD trap with elements for each metric
[[aggregators.zabbix_lld]]
  ## Time between sending LLD traps
  period = "60s"
  ## Numer of executions after all LLDs are sent again
  reset_period = 10
```

### Tags:

No tags are applied by this processor.
