# Telegraf Configuration
#
# Telegraf is entirely plugin driven. All metrics are gathered from the
# declared inputs, and sent to the declared outputs.
#
# Plugins must be declared in here to be active.
# To deactivate a plugin, comment out the name and any variables.
#
# Use 'telegraf -config telegraf.conf -test' to see what metrics a config
# file would generate.
#
# Environment variables can be used anywhere in this config file, simply surround
# them with ${}. For strings the variable must be within quotes (ie, "${STR_VAR}"),
# for numbers and booleans they should be plain (ie, ${INT_VAR}, ${BOOL_VAR})


# Global tags can be specified here in key="value" format.
[global_tags]
  # dc = "us-east-1" # will tag all metrics with dc=us-east-1
  # rack = "1a"
  ## Environment variables can be used as tags, and throughout the config file
  # user = "$USER"

# Configuration for telegraf agent
[agent]
  ## Default data collection interval for all inputs
  interval = "30s"
  ## Rounds collection interval to 'interval'
  ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
  round_interval = true

  ## Telegraf will send metrics to outputs in batches of at most
  ## metric_batch_size metrics.
  ## This controls the size of writes that Telegraf sends to output plugins.
  metric_batch_size = 1000

  ## Maximum number of unwritten metrics per output.  Increasing this value
  ## allows for longer periods of output downtime without dropping metrics at the
  ## cost of higher maximum memory usage.
  metric_buffer_limit = 15000

  ## Collection jitter is used to jitter the collection by a random amount.
  ## Each plugin will sleep for a random time within jitter before collecting.
  ## This can be used to avoid many plugins querying things like sysfs at the
  ## same time, which can have a measurable effect on the system.
  collection_jitter = "0s"

  ## Collection offset is used to shift the collection by the given amount.
  ## This can be be used to avoid many plugins querying constraint devices
  ## at the same time by manually scheduling them in time.
  # collection_offset = "0s"

  ## Default flushing interval for all outputs. Maximum flush_interval will be
  ## flush_interval + flush_jitter
  flush_interval = "30s"
  ## Jitter the flush interval by a random amount. This is primarily to avoid
  ## large write spikes for users running a large number of telegraf instances.
  ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
  flush_jitter = "0s"

  ## Collected metrics are rounded to the precision specified. Precision is
  ## specified as an interval with an integer + unit (e.g. 0s, 10ms, 2us, 4s).
  ## Valid time units are "ns", "us" (or "Âµs"), "ms", "s".
  ##
  ## By default or when set to "0s", precision will be set to the same
  ## timestamp order as the collection interval, with the maximum being 1s:
  ##   ie, when interval = "10s", precision will be "1s"
  ##       when interval = "250ms", precision will be "1ms"
  ##
  ## Precision will NOT be used for service inputs. It is up to each individual
  ## service input to set the timestamp at the appropriate precision.
  precision = "0s"

  ## Log at debug level.
  # debug = false
  ## Log only error level messages.
  # quiet = false

  ## Log target controls the destination for logs and can be one of "file",
  ## "stderr" or, on Windows, "eventlog".  When set to "file", the output file
  ## is determined by the "logfile" setting.
  # logtarget = "file"

  ## Name of the file to be logged to when using the "file" logtarget.  If set to
  ## the empty string then logs are written to stderr.
  # logfile = ""

  ## The logfile will be rotated after the time interval specified.  When set
  ## to 0 no time based rotation is performed.  Logs are rotated only when
  ## written to, if there is no log activity rotation may be delayed.
  # logfile_rotation_interval = "0h"

  ## The logfile will be rotated when it becomes larger than the specified
  ## size.  When set to 0 no size based rotation is performed.
  # logfile_rotation_max_size = "0MB"

  ## Maximum number of rotated archives to keep, any older logs are deleted.
  ## If set to -1, no archives are removed.
  # logfile_rotation_max_archives = 5

  ## Pick a timezone to use when logging or type 'local' for local time.
  ## Example: America/Chicago
  # log_with_timezone = ""

  ## Override default hostname, if empty use os.Hostname()
  hostname = ""
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = false

  ## Method of translating SNMP objects. Can be "netsnmp" (deprecated) which
  ## translates by calling external programs snmptranslate and snmptable,
  ## or "gosmi" which translates using the built-in gosmi library.
  # snmp_translator = "netsnmp"

  ## Name of the file to load the state of plugins from and store the state to.
  ## If uncommented and not empty, this file will be used to save the state of
  ## stateful plugins on termination of Telegraf. If the file exists on start,
  ## the state in the file will be restored for the plugins.
  # statefile = ""

###############################################################################
#                            SECRETSTORE PLUGINS                              #
###############################################################################


# # File based Javascript Object Signing and Encryption based secret-store
# [[secretstores.jose]]
#   ## Unique identifier for the secret-store.
#   ## This id can later be used in plugins to reference the secrets
#   ## in this secret-store via @{<id>:<secret_key>} (mandatory)
#   id = "secretstore"
#
#   ## Directory for storing the secrets
#   path = "/etc/telegraf/secrets"
#
#   ## Password to access the secrets.
#   ## If no password is specified here, Telegraf will prompt for it at startup time.
#   # password = ""


# # Operating System native secret-store
# [[secretstores.os]]
#   ## Unique identifier for the secret-store.
#   ## This id can later be used in plugins to reference the secrets
#   ## in this secret-store via @{<id>:<secret_key>} (mandatory)
#   id = "secretstore"
#
#   ## Keyring Name & Collection
#   ## * Linux: keyring name used for the secrets, collection is unused
#   ## * macOS: keyring specifies the macOS' Keychain name and collection is an
#   ##     optional Keychain service name
#   ## * Windows: keys follow a fixed pattern in the form
#   ##     `<keyring>:<collection>:<key>`. Please keep this in mind when creating
#   ##     secrets with the Windows credential tool.
#   # keyring = "telegraf"
#   # collection = ""
#
#   ## macOS Keychain password
#   ## If no password is specified here, Telegraf will prompt for it at startup
#   ## time.
#   # password = ""
#
#   ## Allow dynamic secrets that are updated during runtime of telegraf
#   # dynamic = false


###############################################################################
#                            OUTPUT PLUGINS                                   #
###############################################################################

# Configuration for sending metrics to vMonitor
[[outputs.vngcloud_vmonitor]]
  url = "https://${VMONITOR_SITE}:443"
  insecure_skip_verify = false
  data_format = "vngcloud_vmonitor"
  timeout = "30s"

  client_id = "${IAM_CLIENT_ID}"
  client_secret = "${IAM_CLIENT_SECRET}"
  iam_url = "${IAM_URL}"




###############################################################################
#                            AGGREGATOR PLUGINS                               #
###############################################################################


# # Calculates a derivative for every field.
[[aggregators.derivative]]
# 	## The period in which to flush the aggregator.
   	period = "60s"
# 	##
# 	## If true, the original metric will be dropped by the
# 	## aggregator and will not get sent to the output plugins.
# 	drop_original = false
# 	##
# 	## This aggregator will estimate a derivative for each field, which is
# 	## contained in both the first and last metric of the aggregation interval.
# 	## Without further configuration the derivative will be calculated with
# 	## respect to the time difference between these two measurements in seconds.
# 	## The formula applied is for every field:
# 	##
# 	##               value_last - value_first
# 	## derivative = --------------------------
# 	##              time_difference_in_seconds
# 	##
# 	## The resulting derivative will be named *fieldname_rate*. The suffix
# 	## "_rate" can be configured by the *suffix* parameter. When using a
# 	## derivation variable you can include its name for more clarity.
# 	# suffix = "_rate"
# 	##
# 	## As an abstraction the derivative can be calculated not only by the time
# 	## difference but by the difference of a field, which is contained in the
# 	## measurement. This field is assumed to be monotonously increasing. This
# 	## feature is used by specifying a *variable*.
# 	## Make sure the specified variable is not filtered and exists in the metrics
# 	## passed to this aggregator!
# 	# variable = ""
# 	##
# 	## When using a field as the derivation parameter the name of that field will
# 	## be used for the resulting derivative, e.g. *fieldname_by_parameter*.
# 	##
# 	## Note, that the calculation is based on the actual timestamp of the
# 	## measurements. When there is only one measurement during that period, the
# 	## measurement will be rolled over to the next period. The maximum number of
# 	## such roll-overs can be configured with a default of 10.
# 	# max_roll_over = 10
# 	##





###############################################################################
#                            INPUT PLUGINS                                    #
###############################################################################


# Read metrics about cpu usage
[[inputs.cpu]]
  ## Whether to report per-cpu stats or not
  percpu = true
  ## Whether to report total system cpu stats or not
  totalcpu = true
  ## If true, collect raw CPU time metrics
  collect_cpu_time = false
  ## If true, compute and report the sum of all non-idle CPU states
  report_active = false
  ## If true and the info is available then add core_id and physical_id tags
  core_tags = false


# Read metrics about disk usage by mount point
[[inputs.disk]]
  ## By default stats will be gathered for all mount points.
  ## Set mount_points will restrict the stats to only the specified mount points.
  # mount_points = ["/"]

  ## Ignore mount points by filesystem type.
  ignore_fs = ["tmpfs", "devtmpfs", "devfs", "iso9660", "overlay", "aufs", "squashfs"]

  ## Ignore mount points by mount options.
  ## The 'mount' command reports options of all mounts in parathesis.
  ## Bind mounts can be ignored with the special 'bind' option.
  # ignore_mount_opts = []


# Read metrics about disk IO by device
[[inputs.diskio]]
  ## By default, telegraf will gather stats for all devices including
  ## disk partitions.
  ## Setting devices will restrict the stats to the specified devices.
  ## NOTE: Globbing expressions (e.g. asterix) are not supported for
  ##       disk synonyms like '/dev/disk/by-id'.
  # devices = ["sda", "sdb", "vd*", "/dev/disk/by-id/nvme-eui.00123deadc0de123"]
  ## Uncomment the following line if you need disk serial numbers.
  # skip_serial_number = false
  #
  ## On systems which support it, device metadata can be added in the form of
  ## tags.
  ## Currently only Linux is supported via udev properties. You can view
  ## available properties for a device by running:
  ## 'udevadm info -q property -n /dev/sda'
  ## Note: Most, but not all, udev properties can be accessed this way. Properties
  ## that are currently inaccessible include DEVTYPE, DEVNAME, and DEVPATH.
  # device_tags = ["ID_FS_TYPE", "ID_FS_USAGE"]
  #
  ## Using the same metadata source as device_tags, you can also customize the
  ## name of the device via templates.
  ## The 'name_templates' parameter is a list of templates to try and apply to
  ## the device. The template may contain variables in the form of '$PROPERTY' or
  ## '${PROPERTY}'. The first template which does not contain any variables not
  ## present for the device is used as the device name tag.
  ## The typical use case is for LVM volumes, to get the VG/LV name instead of
  ## the near-meaningless DM-0 name.
  # name_templates = ["$ID_FS_LABEL","$DM_VG_NAME/$DM_LV_NAME"]


# # Get kernel statistics from /proc/stat
# # This plugin ONLY supports Linux
# [[inputs.kernel]]
#   # no configuration


# Read metrics about memory usage
[[inputs.mem]]
  # no configuration


# # Get the number of processes and group them by status
# # This plugin ONLY supports non-Windows
# [[inputs.processes]]
#   ## Use sudo to run ps command on *BSD systems. Linux systems will read
#   ## /proc, so this does not apply there.
#   use_sudo = false


# # Read metrics about swap memory usage
# [[inputs.swap]]
#   # no configuration


# Read metrics about system load & uptime
[[inputs.system]]
  ## Uncomment to remove deprecated metrics.
  fielddrop = ["uptime_format"]



# # Read metrics about network interface usage
[[inputs.net]]
